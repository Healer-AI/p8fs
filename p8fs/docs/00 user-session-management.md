# User Session Management

## Overview

The P8FS chat API provides session management capabilities that allow conversations to persist across multiple API calls. Session management uses a thread-based grouping model where each API call creates a new Session entity, but sessions can be linked together via a thread_id to maintain conversation context.

## Architecture

### Key Concepts

**Session**: A single API interaction with unique UUID. Each `/v1/chat/completions` call creates a new Session entity.

**Thread**: A conversation grouping identified by thread_id. Multiple sessions can belong to the same thread.

**Thread-based Grouping**: The X-Session-ID header value is stored as the thread_id field, allowing session queries to retrieve all sessions in a conversation.

**Stateless API Design**: Each API call is independent and stateless. Historical context is reconstructed by loading all sessions in the thread.

### Session Model

```python
class Session(BaseModel):
    id: str  # UUID - unique for each API call
    thread_id: str | None  # Groups sessions in a conversation
    userid: str | None
    query: str | None  # User's question from this session
    moment_id: str | None
    session_type: str | None
    metadata: dict  # Stores messages, tokens, model info
    created_at: datetime
```

### Data Flow

1. Client sends request with `X-Session-ID: thread-abc-123`
2. API creates new Session with unique UUID
3. Session.thread_id is set to `thread-abc-123`
4. On subsequent calls with same thread ID:
   - Query all sessions WHERE thread_id = 'thread-abc-123'
   - Load messages from all sessions chronologically
   - Prepend historical messages to current request
   - LLM sees full conversation history

## API Usage

### Starting a New Conversation

```bash
curl -X POST http://localhost:8001/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "X-Tenant-ID: tenant-test" \
  -H "X-Session-ID: my-conversation-123" \
  -d '{
    "model": "gpt-4.1-nano",
    "messages": [
      {"role": "user", "content": "What are the key principles of quantum computing?"}
    ]
  }'
```

The API will:
1. Create a new Session with unique UUID (e.g., `550e8400-e29b-41d4-a716-446655440000`)
2. Set `Session.thread_id = "my-conversation-123"`
3. Process the query and save the response

### Continuing a Conversation

```bash
curl -X POST http://localhost:8001/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "X-Tenant-ID: tenant-test" \
  -H "X-Session-ID: my-conversation-123" \
  -d '{
    "model": "gpt-4.1-nano",
    "messages": [
      {"role": "user", "content": "Can you summarize what we discussed?"}
    ]
  }'
```

The API will:
1. Create another new Session with different UUID (e.g., `661f9511-f3ac-52e5-b827-557766551111`)
2. Set `Session.thread_id = "my-conversation-123"` (same thread)
3. Query: `SELECT * FROM sessions WHERE thread_id = 'my-conversation-123' ORDER BY created_at`
4. Load messages from all sessions in chronological order
5. Prepend historical messages to the current request
6. LLM receives full conversation context

### Session Reload Behavior

When `X-Session-ID` header is provided:

```python
# In chat.py
if session_id:
    # Reload all sessions in this thread
    reloaded_session, historical_messages = await memory_proxy.reload_session(
        thread_id=session_id,  # session_id from header is actually thread_id
        tenant_id=tenant_id,
        decompress_messages=False  # Keep compressed for context efficiency
    )

    if reloaded_session:
        # Load user context from p8fs-user-info Resource
        user_context_dict = await UserContext.load_or_create(tenant_id)
        user_context_msg = UserContext.to_context_message(user_context_dict)

        # Combine: user context + historical messages + new request messages
        historical_messages = [user_context_msg] + historical_messages
```

The combined message structure sent to the LLM:

```
[
  {context_hint},           # Today's date + silent REM LOOKUP instruction
  {user_context_message},   # User summary from p8fs-user-info
  {session_1_user_msg},     # Historical messages from thread
  {session_1_assistant_msg},
  {session_2_user_msg},
  {session_2_assistant_msg},
  {current_request_msg}     # New user message
]
```

## User Context System

### The p8fs-user-info Resource

User context is stored as a special Resource entity with `id="p8fs-user-info"`. This resource contains a summary of the user's activity, preferences, and patterns generated by the dreaming worker.

### UserContext Model

The UserContext class provides static methods for managing user summaries:

```python
class UserContext:
    """User context information stored as Resource entity."""

    @staticmethod
    async def load_or_create(tenant_id: str) -> dict:
        """
        Load existing user context from p8fs-user-info Resource.

        Returns:
            {
                "tenant_id": str,
                "summary": str,  # 200-400 word user summary
                "metadata": {
                    "created_at": ISO timestamp,
                    "total_sessions": int,
                    "total_tokens": int,
                    "sessions_analyzed": int,
                    "moments_available": int,
                    "resources_available": int,
                    "files_available": int,
                    "last_updated": ISO timestamp
                }
            }
        """
        repo = TenantRepository(model_class=Resources, tenant_id=tenant_id)
        resource = await repo.get("p8fs-user-info")

        if resource:
            return {
                "tenant_id": tenant_id,
                "summary": resource.content,
                "metadata": resource.metadata or {}
            }

        # Create placeholder if not exists
        resource = ResourceModel(
            id="p8fs-user-info",
            name="p8fs-user-info",
            category="user_context",
            content="User context not yet summarized. Use summarize_user to generate summary.",
            metadata={
                "created_at": datetime.now().isoformat(),
                "total_sessions": 0,
                "total_tokens": 0
            }
        )
        await repo.upsert(resource)
        return {"tenant_id": tenant_id, "summary": resource.content, "metadata": resource.metadata}

    @staticmethod
    async def update_summary(tenant_id: str, summary: str, metadata: dict | None = None) -> None:
        """
        Update user summary (called by dreaming/summarize_user processes).

        Args:
            tenant_id: Tenant identifier
            summary: Updated user summary (200-400 words)
            metadata: Statistics about analysis (sessions, moments, resources, etc.)
        """
        repo = TenantRepository(model_class=Resources, tenant_id=tenant_id)
        resource = await repo.get("p8fs-user-info")

        if not resource:
            resource = ResourceModel(
                id="p8fs-user-info",
                name="p8fs-user-info",
                category="user_context",
                content=summary,
                metadata=metadata or {}
            )
        else:
            resource.content = summary
            if metadata:
                resource.metadata.update(metadata)

        resource.metadata["last_updated"] = datetime.now().isoformat()
        await repo.upsert(resource)

    @staticmethod
    def to_context_message(user_context: dict) -> dict[str, str]:
        """
        Convert user context to a system message for LLM.

        Returns system message with user summary and stats.
        """
        tenant_id = user_context.get("tenant_id", "unknown")
        summary = user_context.get("summary", "No summary available")
        metadata = user_context.get("metadata", {})

        content = f"""User Context (REM LOOKUP p8fs-user-info):
Tenant ID: {tenant_id}

Summary:
{summary}

Session Stats:
- Total sessions: {metadata.get('total_sessions', 0)}
- Total tokens: {metadata.get('total_tokens', 0):,}
- Last updated: {metadata.get('last_updated', 'Never')}
"""

        return {"role": "system", "content": content}
```

### Generating User Summaries

The dreaming worker provides a `summarize_user()` function that analyzes recent activity to create/update the user summary:

```python
from p8fs.workers.dreaming import summarize_user

# Generate user summary from recent activity
result = await summarize_user(
    tenant_id="tenant-123",
    max_sessions=100,    # Analyze up to 100 recent chat sessions
    max_moments=20,      # Include up to 20 moment keys
    max_resources=20,    # Include up to 20 resource keys
    max_files=10         # Include up to 10 file uploads
)

# Result structure:
{
    "success": True,
    "summary": "User focuses on quantum computing and machine learning...",
    "sessions_analyzed": 75,
    "moments_available": 15,
    "resources_available": 18,
    "files_available": 5,
    "moment_keys": [...],      # Keys for REM LOOKUP
    "resource_keys": [...],    # Keys for REM LOOKUP
    "file_list": [...]         # File URIs for REM LOOKUP
}
```

The function:
1. Loads recent chat sessions, moments, resources, and file uploads
2. Uses LLM to generate a 200-400 word user summary capturing:
   - User interests and focus areas
   - Activity patterns and frequency
   - Key projects and goals
   - Preferred tools and technologies
   - Recent context
3. Includes hints about using REM LOOKUP to retrieve full content
4. Updates the p8fs-user-info Resource with the summary and metadata

### User Summary Structure

Example user summary content:

```
User focuses primarily on quantum computing algorithms and their practical
applications in cryptography. Recent sessions show active development of a
quantum key distribution system using Python and Qiskit. The user frequently
references academic papers on quantum error correction and has uploaded several
research documents related to topological quantum computing.

Activity patterns indicate daily engagement, typically in the afternoon (14:00-18:00 UTC),
with an average of 15-20 chat interactions per session. The user prefers technical
explanations with code examples and mathematical formulations.

Key projects include:
1. Quantum cryptography protocol implementation
2. Error correction simulation framework
3. Research paper on quantum supremacy

Recent uploads include PDF papers on quantum algorithms, Jupyter notebooks with
simulation code, and markdown notes on quantum circuit design.

Use REM LOOKUP with the moment names, resource names, or file URIs listed above
to retrieve full content and learn more about specific items.
```

## REM Query System

### Overview

REM (Resource-Entity-Moment) queries provide a unified interface for retrieving data from the knowledge graph. The system supports multiple query types optimized for different use cases.

### Query Types

**LOOKUP**: Key-based retrieval - O(1) graph lookup for exact entity matches
**SEARCH**: Semantic vector search using embeddings
**FUZZY**: Trigram similarity text search
**SQL**: Standard SELECT queries with WHERE clauses
**TRAVERSE**: Multi-hop graph traversal with edge following

### REM LOOKUP for User Context

The LLM can silently retrieve user information using REM LOOKUP:

```python
# LLM uses this internally (invisible to user)
REM LOOKUP p8fs-user-info
```

This retrieves the full p8fs-user-info Resource containing:
- User summary (200-400 words)
- Session statistics (total_sessions, total_tokens)
- Analysis metadata (sessions_analyzed, moments_available, etc.)
- Timestamps (created_at, last_updated)

### REM Query Parameters

#### LOOKUP Parameters

```python
class LookupParameters:
    key: Union[str, List[str]]  # Entity key(s) to lookup
    table_name: str = "resources"
    tenant_id: Optional[str] = None
    fields: Optional[List[str]] = None  # Specific fields to return
```

Example usage:

```python
# Single key lookup
params = LookupParameters(key="p8fs-user-info")
result = provider.execute(REMQueryPlan(
    query_type=QueryType.LOOKUP,
    parameters=params
))

# Multiple keys lookup
params = LookupParameters(key=["moment-1", "moment-2", "resource-abc"])
results = provider.execute(REMQueryPlan(
    query_type=QueryType.LOOKUP,
    parameters=params
))
```

#### SEARCH Parameters

```python
class SearchParameters:
    query_text: str              # Text to search for
    embedding_field: Optional[str] = None
    limit: int = 10
    threshold: float = 0.7       # Similarity threshold
    metric: str = "cosine"       # Distance metric
```

Example:

```python
# Semantic search for user activities
params = SearchParameters(
    query_text="quantum computing projects",
    limit=10,
    threshold=0.7
)
results = provider.execute(REMQueryPlan(
    query_type=QueryType.SEARCH,
    parameters=params
))
```

#### SQL Parameters

```python
class SQLParameters:
    select_fields: List[str] = ["*"]
    where_clause: Optional[str] = None
    order_by: Optional[List[str]] = None
    limit: Optional[int] = None

    # Read-only validation - prevents DELETE, UPDATE, DROP, etc.
```

Example:

```python
# Find recent sessions
params = SQLParameters(
    where_clause="created_at > NOW() - INTERVAL '7 days'",
    order_by=["-created_at"],
    limit=20
)
results = provider.execute(REMQueryPlan(
    query_type=QueryType.SQL,
    parameters=params
))
```

#### TRAVERSE Parameters

```python
class TraverseParameters:
    initial_query_type: str       # "lookup", "search", or "sql"
    initial_query: Union[str, List[str]]
    edge_types: Optional[List[str]] = None  # Filter by edge type
    max_depth: int = 1            # Number of hops (0=PLAN mode)
    plan_memo: Optional[str] = None  # Agent scratchpad
    direction: str = "outbound"   # "outbound", "inbound", or "both"
    order_by_edge_field: str = "created_at"
    order_direction: str = "DESC"
    result_limit: int = 9
```

Example:

```python
# Find all resources related to a user's moments
params = TraverseParameters(
    initial_query_type="lookup",
    initial_query="moment-quantum-research",
    edge_types=["references", "mentions"],
    max_depth=2,
    result_limit=20
)
result = provider.execute(REMQueryPlan(
    query_type=QueryType.TRAVERSE,
    parameters=params
))
```

### REM Query Response Format

#### LOOKUP Response

```python
[
    {
        "id": "p8fs-user-info",
        "name": "p8fs-user-info",
        "category": "user_context",
        "content": "User summary text...",
        "metadata": {
            "total_sessions": 150,
            "total_tokens": 45000,
            "last_updated": "2025-01-18T10:30:00Z"
        },
        "_entity_type": "public.resources",
        "_table_name": "resources"
    }
]
```

#### SEARCH Response

```python
[
    {
        "id": "resource-123",
        "name": "Quantum Algorithm Notes",
        "content": "...",
        "field_name": "content",
        "distance": 0.23,      # Vector distance
        "similarity": 0.77     # Similarity score (1 - distance)
    }
]
```

#### TRAVERSE Response

```python
{
    "nodes": [
        {
            "name": "moment-1",
            "content": "...",
            "_traverse_depth": 0,
            "_traverse_path": ["moment-1"]
        },
        {
            "name": "resource-abc",
            "content": "...",
            "_traverse_depth": 1,
            "_traverse_path": ["...", "resource-abc"]
        }
    ],
    "stages": [
        {
            "depth": 0,
            "executed": "LOOKUP moment-1",
            "found": {"nodes": 1, "edges": 3}
        },
        {
            "depth": 1,
            "executed": "LOOKUP 3 targets via ['references']",
            "found": {"nodes": 2, "edges": 1},
            "edge_types": {"references": 3}
        }
    ],
    "source_nodes": ["moment-1"],
    "edge_summary": [
        ["moment-1", "references", "resource-abc"],
        ["moment-1", "references", "resource-xyz"]
    ],
    "metadata": {
        "total_nodes": 3,
        "total_edges": 3,
        "unique_nodes": 3,
        "max_depth_reached": 1
    }
}
```

### Using REM LOOKUP in Conversation

The chat API automatically adds a context hint to every request:

```python
context_hint = {
    "role": "user",
    "content": f"Today's date: {today}. You can silently REM LOOKUP p8fs-user-info if you need user preferences or context, but only when relevant. Do not mention this lookup to the user."
}
```

This allows the LLM to:
1. Understand it can access user context via REM LOOKUP
2. Use the lookup silently without mentioning it in responses
3. Retrieve user preferences, goals, and patterns when needed
4. Personalize responses based on user history

## Implementation Details

### Session Creation

```python
# In AuditSessionMixin.start_audit_session()
self._current_session = Session(
    id=str(uuid4()),           # New UUID for each API call
    thread_id=session_id,      # Group sessions by thread
    userid=user_id,
    query=query,
    moment_id=moment_id,
    session_type=session_type,
    metadata={
        "model": model,
        "provider": provider,
        "streaming": streaming,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "system_message": system_message
    }
)
```

### Session Reload

```python
# In AuditSessionMixin.reload_session()
async def reload_session(
    self,
    thread_id: str,
    tenant_id: str,
    decompress_messages: bool = False
) -> tuple[Session | None, list[dict]]:
    # Load ALL sessions in this thread
    repo = TenantRepository(model_class=Session, tenant_id=tenant_id)
    sessions = await repo.select(
        filters={"thread_id": thread_id},
        order_by=["created_at"],  # Chronological order
    )

    # Load and combine messages from all sessions
    message_store = SessionMessageStore(tenant_id=tenant_id)
    all_messages = []

    for session in sessions:
        session_messages = await message_store.load_session_messages(
            session_id=session.id,
            decompress=decompress_messages
        )
        all_messages.extend(session_messages)

    latest_session = sessions[-1] if sessions else None
    return latest_session, all_messages
```

### Message Passing to LLM

```python
# In chat.py
if session_id:
    # Reload thread history
    reloaded_session, historical_messages = await memory_proxy.reload_session(
        thread_id=session_id,
        tenant_id=tenant_id,
        decompress_messages=False
    )

    if reloaded_session:
        # Load user context
        user_context_dict = await UserContext.load_or_create(tenant_id)
        user_context_msg = UserContext.to_context_message(user_context_dict)

        # Combine messages
        historical_messages = [user_context_msg] + historical_messages

# Prepend historical messages to current request
if historical_messages:
    messages = historical_messages + messages

# Add context hint
context_hint = {
    "role": "user",
    "content": f"Today's date: {today}. You can silently REM LOOKUP p8fs-user-info if you need user preferences or context, but only when relevant. Do not mention this lookup to the user."
}
messages = [context_hint] + messages

# Pass to MemoryProxy via context
context.messages = messages
```

### MemoryProxy Integration

```python
# In MemoryProxy.stream()
# Check if pre-built messages are provided
if context and getattr(context, 'messages', None):
    messages = context.messages
    logger.debug(f"Using {len(messages)} pre-built messages from context")
else:
    # Build messages from scratch
    messages = self._build_message_stack(question)
```

## Best Practices

### Thread Management

1. Generate a unique thread ID for each conversation
2. Use consistent thread ID across all calls in the conversation
3. Thread IDs should be stable across app restarts (store in client state)
4. Consider thread lifecycle management (archival, cleanup)

### Performance Optimization

1. Use `decompress_messages=False` for session reload to minimize token usage
2. Implement pagination for very long conversations
3. Consider compressing old messages after a threshold (e.g., 50 messages)
4. Cache user context to avoid repeated database queries

### Message Compression

Long assistant messages can be compressed to save context:

```python
# Automatic compression for messages > 1000 tokens
if len(message["content"]) > 1000:
    compressed_content = f"[COMPRESSED] Use REM LOOKUP {session_id} to retrieve full response"
    message["content"] = compressed_content
```

### User Context Updates

The user summary should be regenerated periodically:

```python
# Run daily or after significant activity
from p8fs.workers.dreaming import summarize_user

# Update user summary
await summarize_user(
    tenant_id="tenant-123",
    max_sessions=100,
    max_moments=20,
    max_resources=20
)
```

### Silent REM LOOKUP

The LLM should use REM LOOKUP transparently:

```
User: "What projects am I working on?"

LLM (internal): REM LOOKUP p8fs-user-info
# Retrieves: "User working on quantum cryptography protocol, error correction framework..."

LLM (response): "Based on your recent activity, you're currently working on three main projects:
1. Quantum cryptography protocol implementation
2. Error correction simulation framework
3. Research paper on quantum supremacy"

# Note: No mention of REM LOOKUP in user-facing response
```

## Security Considerations

1. Thread IDs should not be guessable (use UUIDs)
2. Always validate tenant_id to prevent cross-tenant access
3. Implement rate limiting on session creation
4. Consider implementing thread ownership validation
5. Clean up abandoned threads periodically

## Database Schema

### Sessions Table

```sql
CREATE TABLE sessions (
    id UUID PRIMARY KEY,
    thread_id VARCHAR(255),  -- Groups sessions in conversation
    tenant_id VARCHAR(255) NOT NULL,
    userid VARCHAR(255),
    query TEXT,
    moment_id VARCHAR(255),
    session_type VARCHAR(100),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),

    INDEX idx_thread_id (thread_id),
    INDEX idx_tenant_thread (tenant_id, thread_id)
);
```

### Resources Table (for p8fs-user-info)

```sql
CREATE TABLE resources (
    id VARCHAR(255) PRIMARY KEY,  -- "p8fs-user-info" for user summaries
    tenant_id VARCHAR(255) NOT NULL,
    name VARCHAR(500) NOT NULL,
    category VARCHAR(100),
    content TEXT,
    metadata JSONB,
    graph_paths JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),

    INDEX idx_tenant_id (tenant_id),
    INDEX idx_name (name)
);
```

## Example Integration

### Complete Chat Flow with Session Management

```python
import httpx
import uuid

# Initialize conversation
thread_id = str(uuid.uuid4())
tenant_id = "tenant-123"
api_url = "http://localhost:8001/api/v1/chat/completions"

# First message
response1 = httpx.post(
    api_url,
    headers={
        "X-Tenant-ID": tenant_id,
        "X-Session-ID": thread_id
    },
    json={
        "model": "gpt-4.1-nano",
        "messages": [
            {"role": "user", "content": "Tell me about quantum computing"}
        ]
    }
)

# Second message (continues conversation)
response2 = httpx.post(
    api_url,
    headers={
        "X-Tenant-ID": tenant_id,
        "X-Session-ID": thread_id  # Same thread ID
    },
    json={
        "model": "gpt-4.1-nano",
        "messages": [
            {"role": "user", "content": "What are the practical applications?"}
        ]
    }
)

# LLM has full context from previous message
```

## Testing

See integration test at:
`/Users/sirsh/code/p8fs-modules/p8fs/tests/integration/test_chat_completions_with_session.py`

The test verifies:
1. Session creation with thread_id
2. Session reload with historical messages
3. User context loading and injection
4. LLM receiving full conversation history
5. Proper message ordering and formatting

## Future Enhancements

- Long conversation summarization
- Automatic conversation branching for topic shifts
- Advanced context compression strategies
- Multi-user conversation support
