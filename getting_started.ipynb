{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P8FS Getting Started - Build an Agent\n",
    "\n",
    "Let's build a weather agent with P8FS MemoryProxy.\n",
    "\n",
    "**Prerequisites:** Start PostgreSQL first:\n",
    "```bash\n",
    "cd p8fs && docker-compose up postgres -d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 21:25:32.366\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.repository.SystemRepository\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mInitialized SystemRepository for Session without tenant scoping\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.367\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.repository.SystemRepository\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mInitialized SystemRepository for Resources without tenant scoping\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.367\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.repository.SystemRepository\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mInitialized SystemRepository for Tenant without tenant scoping\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.base_proxy\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mInitialized BaseProxy\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mInitialized FunctionHandler\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.368\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function get_entities\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.369\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function search_resources\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.369\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function get_recent_tenant_uploads\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.memory_proxy\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mInitialized MemoryProxy with model context: None\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.431\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: \n",
      "                SELECT * FROM sessions \n",
      "                WHERE tenant_id = %s \n",
      "                ORDER...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.workers.dreaming_repository\u001b[0m:\u001b[36mget_sessions\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRetrieved 0 sessions for tenant tenant-zwwon1x8kni\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.489\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: \n",
      "                SELECT * FROM resources \n",
      "                WHERE tenant_id = %s \n",
      "                ORDE...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.workers.dreaming_repository\u001b[0m:\u001b[36mget_resources\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mRetrieved 0 resources for tenant tenant-zwwon1x8kni\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.545\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: \n",
      "                SELECT * FROM tenants \n",
      "                WHERE tenant_id = %s \n",
      "                LIMIT ...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mp8fs.workers.dreaming_repository\u001b[0m:\u001b[36mget_tenant_profile\u001b[0m:\u001b[36m86\u001b[0m - \u001b[33m\u001b[1mNo tenant profile found for tenant-zwwon1x8kni\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# To use the cluster tidb\n",
    "  # from p8fs folder `docker compose down tidb`\n",
    "  # and you can connect to the cluster with first forwarding a port in a new terminal\n",
    "  # kc port-forward svc/fresh-cluster-tidb -n tikv-cluster 4000:4000\n",
    "# then set the provider\n",
    "# P8FS_STORAGE_PROVIDER=tidb\n",
    "import os\n",
    "#os.environ['P8FS_STORAGE_PROVIDER'] = 'tidb'\n",
    "#os.environ['P8FS_TIDB_DATABASE']='models'\n",
    "from p8fs.workers.dreaming import DreamingWorker\n",
    "dreaming_worker = DreamingWorker()\n",
    "user_data = await dreaming_worker.collect_user_data('tenant-zwwon1x8kni')\n",
    "if user_data:\n",
    "    print(len(user_data.resources))\n",
    "else:\n",
    "    print('no data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tenant-test'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from p8fs.models import AbstractModel\n",
    "from p8fs.services.llm.memory_proxy import MemoryProxy\n",
    "from p8fs.services.llm.models import CallingContext, BatchCallingContext\n",
    "from p8fs import settings\n",
    "tenant_id = settings.default_tenant_id\n",
    "tenant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 21:25:32.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.base_proxy\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mInitialized BaseProxy\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mInitialized FunctionHandler\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function get_entities\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function search_resources\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.572\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function get_recent_tenant_uploads\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.573\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function get_forecast\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.573\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.memory_proxy\u001b[0m:\u001b[36m_register_model_functions\u001b[0m:\u001b[36m271\u001b[0m - \u001b[34m\u001b[1mRegistered function: get_forecast\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.574\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mAdded function get_weather\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.574\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.memory_proxy\u001b[0m:\u001b[36m_register_model_functions\u001b[0m:\u001b[36m271\u001b[0m - \u001b[34m\u001b[1mRegistered function: get_weather\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:32.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.memory_proxy\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mInitialized MemoryProxy with model context: default.WeatherAgent\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#subclass abstract model\n",
    "class WeatherAgent(AbstractModel):\n",
    "    \"\"\"You are an agent that provides some weather services along with a joke or a poem as your party piece\"\"\"\n",
    "    @classmethod\n",
    "    def get_weather(self, location: str, units: str = \"fahrenheit\"):\n",
    "        \"\"\"Get current weather for a location.\"\"\"\n",
    "        temp = 72 if units == \"fahrenheit\" else 22\n",
    "        return {\n",
    "            \"location\": location,\n",
    "            \"temperature\": temp,\n",
    "            \"units\": units,\n",
    "            \"conditions\": \"sunny\"\n",
    "        }\n",
    "    @classmethod\n",
    "    def get_forecast(self, location: str, days: int = 3):\n",
    "        \"\"\"Get weather forecast for a location.\"\"\"\n",
    "        return {\n",
    "            \"location\": location,\n",
    "            \"days\": days,\n",
    "            \"forecast\": [\n",
    "                {\"day\": i+1, \"high\": 75+i, \"low\": 60+i, \"conditions\": \"sunny\"}\n",
    "                for i in range(days)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Create agent and wrap with MemoryProxy\n",
    "agent = MemoryProxy(WeatherAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'paris',\n",
       " 'temperature': 72,\n",
       " 'units': 'fahrenheit',\n",
       " 'conditions': 'sunny'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = agent._function_handler._functions['get_weather']\n",
    "F('paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 21:25:32.583\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.memory_proxy\u001b[0m:\u001b[36mstream\u001b[0m:\u001b[36m557\u001b[0m - \u001b[34m\u001b[1mStreaming agentic loop iteration 1/10\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:33.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.function_handler\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mExecuted function 'get_weather' successfully\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:33.713\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.memory_proxy\u001b[0m:\u001b[36m_execute_function_calls\u001b[0m:\u001b[36m483\u001b[0m - \u001b[34m\u001b[1mFunction get_weather executed successfully in streaming mode\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:33.714\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.memory_proxy\u001b[0m:\u001b[36mstream\u001b[0m:\u001b[36m557\u001b[0m - \u001b[34m\u001b[1mStreaming agentic loop iteration 2/10\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:36.944\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: INSERT INTO sessions (id, created_at, updated_at, name, query, user_rating, agent, parent_session_id...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:36.964\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.repository.BaseRepository\u001b[0m:\u001b[36mupsert\u001b[0m:\u001b[36m404\u001b[0m - \u001b[34m\u001b[1mSuccessfully async upserted 1 Session entities\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 21:25:37.559\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: \n",
      "            INSERT INTO embeddings.sessions_embeddings \n",
      "            (id, entity_id, field_name, emb...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.repository.BaseRepository\u001b[0m:\u001b[36m_generate_embeddings_for_entities\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated and stored 1 embeddings in batch\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.607\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.audit_mixin\u001b[0m:\u001b[36mstart_audit_session\u001b[0m:\u001b[36m67\u001b[0m - \u001b[34m\u001b[1mStarted audit session c4f59dc6-c493-4f26-be75-e50dd98413ad\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.services.llm.audit_mixin\u001b[0m:\u001b[36mtrack_usage\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mSession c4f59dc6-c493-4f26-be75-e50dd98413ad: +5p +32c ($0.0021) Total: 37 tokens, $0.0021\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.services.llm.audit_mixin\u001b[0m:\u001b[36mend_audit_session\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mEnded audit session c4f59dc6-c493-4f26-be75-e50dd98413ad: 37 tokens, 0 function calls, $0.0021, 0.70s\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.647\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: INSERT INTO sessions (id, created_at, updated_at, name, query, user_rating, agent, parent_session_id...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.675\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.repository.BaseRepository\u001b[0m:\u001b[36mupsert\u001b[0m:\u001b[36m404\u001b[0m - \u001b[34m\u001b[1mSuccessfully async upserted 1 Session entities\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.712\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: INSERT INTO sessions (id, created_at, updated_at, name, query, user_rating, agent, parent_session_id...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.737\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.repository.BaseRepository\u001b[0m:\u001b[36mupsert\u001b[0m:\u001b[36m404\u001b[0m - \u001b[34m\u001b[1mSuccessfully async upserted 1 Session entities\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 21:25:37.899\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: \n",
      "            INSERT INTO embeddings.sessions_embeddings \n",
      "            (id, entity_id, field_name, emb...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:37.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.repository.BaseRepository\u001b[0m:\u001b[36m_generate_embeddings_for_entities\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated and stored 1 embeddings in batch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The current weather in Chicago is sunny with a temperature of 72Â°F.\\n\\nAnd here's a quick weather-themed joke for you:\\nWhy did the sun go to school? To get a little brighter!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 21:25:38.432\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mp8fs.providers.postgresql\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m294\u001b[0m - \u001b[34m\u001b[1mExecuting query: \n",
      "            INSERT INTO embeddings.sessions_embeddings \n",
      "            (id, entity_id, field_name, emb...\u001b[0m\n",
      "\u001b[32m2025-10-10 21:25:38.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mp8fs.repository.BaseRepository\u001b[0m:\u001b[36m_generate_embeddings_for_entities\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated and stored 1 embeddings in batch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Normal Mode - Complete Response\n",
    "context = CallingContext(\n",
    "    model=\"gpt-4.1\" ,tenant_id = tenant_id\n",
    ")\n",
    "\n",
    "response = await agent.run(\"What's the weather in Chicago?\", context)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming Mode - Real-time Response\n",
    "stream_context = CallingContext(stream=True)\n",
    "\n",
    "async for chunk in agent.stream(\"Tell me about Miami weather\", stream_context):\n",
    "    if \"choices\" in chunk:\n",
    "        content = chunk[\"choices\"][0].get(\"delta\", {}).get(\"content\", \"\")\n",
    "        print(content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Mode - Multiple Questions\n",
    "questions = [\n",
    "    \"Weather in Boston?\",\n",
    "    \"3-day forecast for Seattle?\",\n",
    "    \"Temperature in Phoenix in Celsius?\"\n",
    "]\n",
    "\n",
    "batch_context = BatchCallingContext(\n",
    "    model=\"gpt-5\",\n",
    "    system_message=\"You are a weather assistant.\"\n",
    ")\n",
    "\n",
    "result = await agent.batch(questions, batch_context)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You just learned the P8FS pattern:\n",
    "\n",
    "```python\n",
    "# 1. Create your agent class subclassing pydantic base model or our abstract types\n",
    "class YourAgent(AbstractEntityModel):\n",
    "    async def your_function(self, param: str):\n",
    "        return {\"result\": \"data\"}\n",
    "\n",
    "# 2. Wrap with MemoryProxy\n",
    "agent = YourAgent\n",
    "memory = MemoryProxy(agent)\n",
    "\n",
    "# 3. Use in three modes\n",
    "await memory.run(question, context)              # Normal\n",
    "async for chunk in memory.stream(q, context):   # Streaming  \n",
    "await memory.batch(questions, batch_context)    # Batch\n",
    "```\n",
    "\n",
    "**Next:** Add your LLM API key for real AI responses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sessions and Files\n",
    "- when you use memory proxy directly or via the completions API, sessions are audited which feed into dreaming.\n",
    "- You can also process files locally to test simulating what happens when files are uploaded and processed in Seaweed; we index the file in Files table and we create chunks in Resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p8fs.repository.TenantRepository import TenantRepository\n",
    "from p8fs.repository.SystemRepository import SystemRepository\n",
    "from p8fs.models.p8 import Session, SessionType\n",
    "from p8fs.providers import get_provider\n",
    "\n",
    "# Create SystemRepository (bypasses tenant isolation)\n",
    "repo = SystemRepository(Session)\n",
    "\n",
    "recent_sessions = repo.execute(\"\"\"\n",
    "  SELECT * FROM sessions\n",
    "  ORDER BY created_at DESC\n",
    "  LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "recent_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the CLI to process files in the ./Samples folder or any file you choose\n",
    "- the cli allows processing entire folders too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv run -m p8fs.cli process ./p8fs/tests/sample_data/content/Sample.md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv run -m p8fs.cli process ./p8fs/tests/sample_data/content/Sample.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv run -m p8fs.cli process ./p8fs/tests/sample_data/content/Sample.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv run -m p8fs.cli process ./p8fs/tests/sample_data/content/Sample.docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to Dreaming\n",
    "- if we have sessions and resources we can use this as content to terst the dreaming agent\n",
    "- normally this is managed by a process the dreaming worker and you can use the cli to run this as the docs show\n",
    "- below we will use the dreaming worker code to get the data bundle and then simple use the Dreaming worker to process the data\n",
    "- From here you can build your agents or play with the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Dreaming Example - All Modes Working\n",
    "\n",
    "This example demonstrates the full dreaming functionality with MemoryProxy and DreamingAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Dreaming Example - Simple Version\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from uuid import uuid4\n",
    "from p8fs.models.agentlets import DreamModel\n",
    "from p8fs.services.llm import MemoryProxy, CallingContext, BatchCallingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p8fs.workers.dreaming import DreamingWorker\n",
    "\n",
    "repo = TenantRepository(Session, tenant_id)\n",
    "#dreaming worker just uses to fetch user data as we do in the worker process e.g. 24 hours of data\n",
    "dreaming_worker = DreamingWorker()\n",
    "agent = MemoryProxy(DreamModel)\n",
    "\n",
    "# Collect real user data using dreaming worker utility as the scheduled job would do\n",
    "# in this case our own activity can create these records:> files processed and chats had.\n",
    "user_data = await dreaming_worker.collect_user_data(tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add any args required\n",
    "from IPython.display import Markdown\n",
    "context = CallingContext(tenant_id=tenant_id,)\n",
    "\n",
    "#in practice dreaming worker should handle large user data batches\n",
    "query = f\"\"\"Analyze this user activity data: {user_data.model_dump()} Provide key insights and recommendations.\"\"\"\n",
    "\n",
    "response = await agent.run(query, context)\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async for chunk in memory_proxy.stream(query, context):\n",
    "#     chunks += 1\n",
    "#     #TODO print friendly sse\n",
    "#     if chunks > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostly we do dreaming in batch mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_context = BatchCallingContext(\n",
    "    model=\"gpt-5\", \n",
    "    tenant_id=tenant_id\n",
    ")\n",
    "\n",
    "batch_response = await agent.batch(query, batch_context)\n",
    "batch_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
